{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d15ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\william\\miniconda3\\envs\\ia\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\william\\miniconda3\\envs\\ia\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\william\\miniconda3\\envs\\ia\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\william\\miniconda3\\envs\\ia\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\william\\miniconda3\\envs\\ia\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\william\\miniconda3\\envs\\ia\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\william\\miniconda3\\envs\\ia\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\william\\miniconda3\\envs\\ia\\lib\\site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\william\\miniconda3\\envs\\ia\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\william\\miniconda3\\envs\\ia\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d2a646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6d2b731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado: 199 mensajes\n"
     ]
    }
   ],
   "source": [
    "# 1. Cargar el conjunto de datos \n",
    "csv_path = \"spam_dataset_200.csv\"\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"No se encontró {csv_path}. Asegúrate de que el archivo exista.\")\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"Dataset cargado: {len(df)} mensajes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39630cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: 139 mensajes, Prueba: 60 mensajes\n"
     ]
    }
   ],
   "source": [
    "# 2. Separar datos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['message'], df['label'], test_size=0.3, random_state=42\n",
    ")\n",
    "print(f\"Entrenamiento: {len(X_train)} mensajes, Prueba: {len(X_test)} mensajes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a99c6aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Implementar el clasificador Naive Bayes\n",
    "class CustomNaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.prior = {}  # P(C)\n",
    "        self.likelihood = {}  # P(w|C)\n",
    "        self.vocab = set()  # Vocabulario\n",
    "        self.class_counts = defaultdict(int)  # Conteo de mensajes por clase\n",
    "        self.word_counts = defaultdict(lambda: defaultdict(int))  # Conteo de palabras por clase\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        \"\"\"Convertir texto a minúsculas, eliminar caracteres especiales y tokenizar.\"\"\"\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text.lower())\n",
    "        return text.split()\n",
    "    \n",
    "    def fit(self, messages, labels):\n",
    "        \"\"\"Calcular probabilidades a priori y condicionales.\"\"\"\n",
    "        # Calcular probabilidades a priori\n",
    "        total_messages = len(labels)\n",
    "        for label in set(labels):\n",
    "            self.prior[label] = sum(1 for l in labels if l == label) / total_messages\n",
    "        \n",
    "        # Construir vocabulario y contar palabras\n",
    "        for message, label in zip(messages, labels):\n",
    "            self.class_counts[label] += 1\n",
    "            words = self.preprocess(message)\n",
    "            for word in words:\n",
    "                self.word_counts[label][word] += 1\n",
    "                self.vocab.add(word)\n",
    "        \n",
    "        # Calcular probabilidades condicionales con suavizado de Laplace\n",
    "        for label in self.prior:\n",
    "            self.likelihood[label] = {}\n",
    "            total_words = sum(self.word_counts[label][word] for word in self.vocab)\n",
    "            vocab_size = len(self.vocab)\n",
    "            for word in self.vocab:\n",
    "                self.likelihood[label][word] = (\n",
    "                    (self.word_counts[label][word] + 1) / (total_words + vocab_size)\n",
    "                )\n",
    "    \n",
    "    def calculate_posterior(self, message):\n",
    "        \"\"\"Calcular probabilidades posteriores P(C|M) para un mensaje.\"\"\"\n",
    "        words = self.preprocess(message)\n",
    "        posteriors = {}\n",
    "        \n",
    "        # Calcular log-probabilidad para cada clase\n",
    "        for label in self.prior:\n",
    "            log_posterior = np.log(self.prior[label])\n",
    "            for word in words:\n",
    "                if word in self.vocab:\n",
    "                    log_posterior += np.log(self.likelihood[label][word])\n",
    "                else:\n",
    "                    # Suavizado para palabras desconocidas\n",
    "                    log_posterior += np.log(1 / (sum(self.word_counts[label].values()) + len(self.vocab)))\n",
    "            posteriors[label] = log_posterior\n",
    "        \n",
    "        # Normalizar a probabilidades\n",
    "        max_log = max(posteriors.values())\n",
    "        exp_sums = sum(np.exp(log_p - max_log) for log_p in posteriors.values())\n",
    "        normalized_posteriors = {\n",
    "            label: np.exp(log_p - max_log) / exp_sums for label, log_p in posteriors.items()\n",
    "        }\n",
    "        \n",
    "        return normalized_posteriors\n",
    "    \n",
    "    def predict(self, messages):\n",
    "        \"\"\"Predecir la clase y devolver probabilidades posteriores para cada mensaje.\"\"\"\n",
    "        predictions = []\n",
    "        posterior_probs = []\n",
    "        \n",
    "        for message in messages:\n",
    "            posteriors = self.calculate_posterior(message)\n",
    "            predicted_label = max(posteriors, key=posteriors.get)\n",
    "            predictions.append(predicted_label)\n",
    "            posterior_probs.append(posteriors)\n",
    "        \n",
    "        return predictions, posterior_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3289c5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probabilidades posteriores del clasificador personalizado (primeros 5 mensajes):\n",
      "\n",
      "Mensaje 1: Descuento del 35% en tu compra\n",
      "Predicción: spam\n",
      "Probabilidades posteriores: {'spam': np.float64(0.9904198501169023), 'no_spam': np.float64(0.009580149883097664)}\n",
      "\n",
      "Mensaje 2: Felicidades, ganaste un iPhone\n",
      "Predicción: spam\n",
      "Probabilidades posteriores: {'spam': np.float64(0.9980774812050127), 'no_spam': np.float64(0.0019225187949871928)}\n",
      "\n",
      "Mensaje 3: Almuerzo en factura este reunión\n",
      "Predicción: no_spam\n",
      "Probabilidades posteriores: {'spam': np.float64(7.446141856409593e-05), 'no_spam': np.float64(0.999925538581436)}\n",
      "\n",
      "Mensaje 4: Tu casa ha sido enviado\n",
      "Predicción: no_spam\n",
      "Probabilidades posteriores: {'spam': np.float64(0.00010211569266414951), 'no_spam': np.float64(0.9998978843073357)}\n",
      "\n",
      "Mensaje 5: Última chance para oferta de coche\n",
      "Predicción: spam\n",
      "Probabilidades posteriores: {'spam': np.float64(0.9986857001446129), 'no_spam': np.float64(0.0013142998553871358)}\n"
     ]
    }
   ],
   "source": [
    "# 4. Entrenar y evaluar el clasificador personalizado\n",
    "custom_nb = CustomNaiveBayes()\n",
    "custom_nb.fit(X_train, y_train)\n",
    "custom_predictions, custom_posteriors = custom_nb.predict(X_test)\n",
    "\n",
    "# Mostrar probabilidades posteriores para los primeros 5 mensajes\n",
    "print(\"\\nProbabilidades posteriores del clasificador personalizado (primeros 5 mensajes):\")\n",
    "for i, (message, pred, probs) in enumerate(zip(X_test[:5], custom_predictions[:5], custom_posteriors[:5])):\n",
    "    print(f\"\\nMensaje {i+1}: {message}\")\n",
    "    print(f\"Predicción: {pred}\")\n",
    "    print(f\"Probabilidades posteriores: {probs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56c7d190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probabilidades posteriores de scikit-learn (primeros 5 mensajes):\n",
      "\n",
      "Mensaje 1: Descuento del 35% en tu compra\n",
      "Predicción: spam\n",
      "Probabilidades posteriores: {'no_spam': 0.0070, 'spam': 0.9930}\n",
      "\n",
      "Mensaje 2: Felicidades, ganaste un iPhone\n",
      "Predicción: spam\n",
      "Probabilidades posteriores: {'no_spam': 0.0018, 'spam': 0.9982}\n",
      "\n",
      "Mensaje 3: Almuerzo en factura este reunión\n",
      "Predicción: no_spam\n",
      "Probabilidades posteriores: {'no_spam': 0.9999, 'spam': 0.0001}\n",
      "\n",
      "Mensaje 4: Tu casa ha sido enviado\n",
      "Predicción: no_spam\n",
      "Probabilidades posteriores: {'no_spam': 0.9999, 'spam': 0.0001}\n",
      "\n",
      "Mensaje 5: Última chance para oferta de coche\n",
      "Predicción: spam\n",
      "Probabilidades posteriores: {'no_spam': 0.0012, 'spam': 0.9988}\n",
      "\n",
      "Resultados del clasificador personalizado:\n",
      "Precisión: 1.0\n",
      "\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     no_spam       1.00      1.00      1.00        31\n",
      "        spam       1.00      1.00      1.00        29\n",
      "\n",
      "    accuracy                           1.00        60\n",
      "   macro avg       1.00      1.00      1.00        60\n",
      "weighted avg       1.00      1.00      1.00        60\n",
      "\n",
      "\n",
      "Resultados del clasificador de scikit-learn:\n",
      "Precisión: 1.0\n",
      "\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     no_spam       1.00      1.00      1.00        31\n",
      "        spam       1.00      1.00      1.00        29\n",
      "\n",
      "    accuracy                           1.00        60\n",
      "   macro avg       1.00      1.00      1.00        60\n",
      "weighted avg       1.00      1.00      1.00        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Comparar con scikit-learn\n",
    "# Vectorización de los mensajes\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Entrenar modelo de scikit-learn\n",
    "sklearn_nb = MultinomialNB()\n",
    "sklearn_nb.fit(X_train_vec, y_train)\n",
    "sklearn_predictions = sklearn_nb.predict(X_test_vec)\n",
    "sklearn_posteriors = sklearn_nb.predict_proba(X_test_vec)\n",
    "\n",
    "# Mostrar probabilidades posteriores de scikit-learn para los primeros 5 mensajes\n",
    "print(\"\\nProbabilidades posteriores de scikit-learn (primeros 5 mensajes):\")\n",
    "for i, (message, pred, probs) in enumerate(zip(X_test[:5], sklearn_predictions[:5], sklearn_posteriors[:5])):\n",
    "    print(f\"\\nMensaje {i+1}: {message}\")\n",
    "    print(f\"Predicción: {pred}\")\n",
    "    print(f\"Probabilidades posteriores: {{'no_spam': {probs[0]:.4f}, 'spam': {probs[1]:.4f}}}\")\n",
    "\n",
    "# Mostrar métricas de evaluación\n",
    "print(\"\\nResultados del clasificador personalizado:\")\n",
    "print(\"Precisión:\", accuracy_score(y_test, custom_predictions))\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(y_test, custom_predictions))\n",
    "\n",
    "print(\"\\nResultados del clasificador de scikit-learn:\")\n",
    "print(\"Precisión:\", accuracy_score(y_test, sklearn_predictions))\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(y_test, sklearn_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
