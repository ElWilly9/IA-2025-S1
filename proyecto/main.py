import os
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains import RetrievalQA
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
import pdfplumber
from langchain.schema import Document
import speech_recognition as sr
import pyttsx3
import logging
import time

# Cargar variables de entorno
load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")  # Aseg√∫rate de tener .env con GEMINI_API_KEY

# Directorio con PDFs
DOCS_DIR = "./data/"

# Text Processing
CHUNK_SIZE = 2000  
CHUNK_OVERLAP = 200  

PERSIST_DIR = "./chroma_db"

# Paso 1: Cargar y chunkear PDFs
def load_and_chunk_pdfs():
    documents = []
    for filename in os.listdir(DOCS_DIR):
        if filename.endswith(".pdf"):
            file_path = os.path.join(DOCS_DIR, filename)
            with pdfplumber.open(file_path) as pdf:
                for page_num, page in enumerate(pdf.pages):
                    # Extraer texto
                    text = page.extract_text()
                    
                    # Extraer tablas
                    tables = page.extract_tables()
                    table_text = ""
                    for table in tables:
                        for row in table:
                            # Filtrar valores None y convertir a string
                            row_text = " | ".join(str(cell) if cell is not None else "" for cell in row)
                            table_text += row_text + "\n"
                    
                    # Combinar texto y tablas
                    combined_text = f"{text}\n\nTablas:\n{table_text}"
                    
                    # Crear documento con metadatos
                    doc = Document(
                        page_content=combined_text,
                        metadata={
                            "source": filename,
                            "page": page_num + 1
                        }
                    )
                    documents.append(doc)
    
    # Dividir documentos en fragmentos
    text_splitter = CharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP,
        length_function=len,
        separator="\n"  # Dividir por l√≠neas para mantener coherencia
    )
    chunks = text_splitter.split_documents(documents)
    return chunks

# Paso 2: Crear base de datos vectorial
def create_or_load_vector_store(chunks, persist_directory=PERSIST_DIR, force_reload=False):
    embeddings = HuggingFaceEmbeddings(model_name="multi-qa-distilbert-cos-v1")
    if force_reload and os.path.exists(persist_directory):
        import shutil
        shutil.rmtree(persist_directory)

    if os.path.exists(persist_directory) and os.listdir(persist_directory):
        vector_store = Chroma(
            collection_name="bajaj_boxer",
            embedding_function=embeddings,
            persist_directory=persist_directory
        )
    else:
        vector_store = Chroma.from_documents(
            chunks,
            embeddings,
            collection_name="bajaj_boxer",
            persist_directory=persist_directory
        )
    return vector_store

# Paso 3: Configurar el sistema RAG
def setup_rag(vector_store):
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        google_api_key=api_key,
        temperature=0.2
    )
    
    # Prompt personalizado para tono natural y cordial
    prompt_template = """
    Eres un asistente experto en motocicletas Bajaj Boxer CT100 KS. 
    Tu trabajo es ayudar a los usuarios con informaci√≥n t√©cnica, mantenimiento y operaci√≥n de esta motocicleta espec√≠fica.

    CONTEXTO RELEVANTE DE LA DOCUMENTACI√ìN:
    {context}

    PREGUNTA DEL USUARIO: {question}

    INSTRUCCIONES PARA TU RESPUESTA:
    - Responde √öNICAMENTE sobre la Bajaj Boxer CT100 KS y si hablaras de otra moto, especificalo
    - Usa un tono cordial, natural y profesional en espa√±ol
    - Basa tu respuesta en la informaci√≥n del contexto proporcionado
    - Si la informaci√≥n est√° en una tabla, incluye los valores espec√≠ficos
    - Si la informaci√≥n no est√° en el contexto, dilo claramente
    - Proporciona respuestas pr√°cticas y √∫tiles para el usuario
    - Incluye detalles t√©cnicos relevantes cuando sea apropiado
    - Si mencionas especificaciones t√©cnicas, cita los valores exactos
    - Mant√©n la respuesta completa pero concisa, no la hagas tan extensa

    RESPUESTA:
    """ 
    prompt = PromptTemplate(input_variables=["question", "context"], template=prompt_template)
    
    retriever = vector_store.as_retriever(search_kwargs={"k": 4})
    rag_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True,
        chain_type_kwargs={"prompt": prompt}
    )
    return rag_chain

# Paso 4: Ciclo interactivo en consola
def main():
    print("¬øQuieres (C)argar la base vectorial existente o (R)ecrearla con los documentos actuales?")
    op = input("Escribe C para cargar o R para recrear: ").strip().lower()
    force_reload = (op == "r")

    if force_reload:
        print("Cargando y procesando documentos...")
        chunks = load_and_chunk_pdfs()
        print(f"Se cargaron {len(chunks)} fragmentos de documentos.")
        print_document_samples(chunks)
    else:
        chunks = []

    print("Cargando base de datos vectorial...")
    vector_store = create_or_load_vector_store(chunks, force_reload=force_reload)

    print("Configurando sistema RAG...")
    rag_chain = setup_rag(vector_store)

    print("\n¬°Asistente virtual para Bajaj Boxer CT100 KS listo!")
    print("Di tu pregunta (o 'salir' para terminar):")

    while True:
        query = escuchar_query()
        if not query:
            continue
        if query.lower() == "salir":
            break

        result = rag_chain.invoke({"query": query})
        respuesta = result["result"]
        print("\nRespuesta ü§ñ:", respuesta)
        decir_respuesta(respuesta)

        # Preguntar si desea hacer otra consulta o salir
        opcion = input("\n¬øQuieres hacer otra consulta? (S para s√≠, cualquier otra tecla para salir): ").strip().lower()
        if opcion != "s":
            break

    print("¬°Gracias por usar el asistente!")

def print_document_samples(chunks):
    print("\nMuestras de documentos cargados:")
    for i, chunk in enumerate(chunks[:3]):  # Mostrar primeros 3 chunks
        print(f"\nChunk {i+1}:")
        print(f"Fuente: {chunk.metadata.get('source')}")
        print(f"P√°gina: {chunk.metadata.get('page')}")
        print("Contenido:")
        print(chunk.page_content[:200] + "...")  # Primeros 200 caracteres

def escuchar_query():
    r = sr.Recognizer()
    with sr.Microphone() as source:
        print("preparate para hablar en 3...")
        time.sleep(1)
        print("preparate para hablar en 2...")
        time.sleep(1)
        print("preparate para hablar en 1... ")
        time.sleep(1)
        print("Habla ahora. La grabaci√≥n terminar√° cuando te quedes en silencio...")
        time.sleep(0.5)
        r.adjust_for_ambient_noise(source, duration=1.3)
        audio = r.listen(source, timeout=None, phrase_time_limit=None)
        os.makedirs("audio", exist_ok=True)
        with open("audio/query.wav", "wb") as f:
            f.write(audio.get_wav_data())
        try:
            print("Espere un momento, procesando...")
            text = r.recognize_google(audio, language='es-ES')
            print("Texto reconocido:", text)
            return text
        except:
            print("Lo siento, no pude entender el audio.")
            return None

def decir_respuesta(texto):
    engine = pyttsx3.init()
    engine.setProperty('rate', 170)
    engine.setProperty('volume', 1)
    os.makedirs("audio", exist_ok=True)
    engine.say(texto)
    engine.save_to_file(texto, "audio/answer.mp3")
    engine.runAndWait()

if __name__ == "__main__":
    logging.getLogger("pdfminer").setLevel(logging.ERROR) #para que no salga los warnings de pdflumber
    main()